<!doctype html>
<!-- 
##############################################################
Ignore this boilerplate if you're just trying to edit the text.
Skip to the part that says 'The real text begins here'
##############################################################

Based on this theme: https://github.com/broccolini/dinky , which mentioned that attribution is appreciated. Thanks, broccolini!
-->
<html lang="en">
  <head>
    <base target="_blank">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>remote_refocus by AMSikking</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/prism.css">
    <!--[if lt IE 9]>
    <script src="javascript/html5shiv/html5shiv.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
      <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
    <![endif]-->
    <script src="javascript/scale-fix/scale.fix.js"></script>
    <script src="javascript/python-highlighting/prism.js"></script>
    <script async src="javascript/Minimal-MathJax/MathJax.js?config=TeX-AMS_CHTML"></script>
    <script src="javascript/update_figures.js"></script>
    <script src="javascript/reference_list/reference_list.js"></script>
    <script src="javascript/google-analytics/analytics.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1 class="header">4D imaging via remote refocus</h1>
        <ul>
          <li class="download"><a class="buttons" href="https://github.com/AMSikking/remote_refocus/zipball/master">Download ZIP</a></li>
          <li><a class="buttons github" href="https://github.com/AMSikking/remote_refocus">View On GitHub</a></li>
          <li><a class="buttons pdf" href="./remote_refocus%20by%20AMSikking.pdf">Download PDF</a></li>
        </ul>
        <p class="header" style="text-align:left;">This project is maintained by <a class="header name" href="https://github.com/AMSikking">AMSikking</a>, and was funded by <a class="header name" href="https://www.calicolabs.com/">Calico Life Sciences LLC</a></p>
      </header>
<!-- 
##############################################################
The real text begins here.
##############################################################
 -->
<section>
<h1>Research article</h1>
<h3 class="onlyprint">
Note that this is a limited PDF or print version; animated and interactive figures are disabled. For the full version of this article, please visit <a href="https://amsikking.github.io/remote_refocus">https://amsikking.github.io/remote_refocus</a></h3>
<noscript>
<h3>Your browser doesn't seem to support Javascript. This document uses Javascript for interactive figures, math typesetting, and to automatically generate the reference list. Either activate Javascript, or use the "Download PDF" link above if you want properly typeset math and a reference list.</h3></noscript>
<h2>Remote refocus enables class-leading spatiotemporal resolution in 4D optical microscopy</h2>
<p class="author_list">Alfred Millett-Sikking<sup>1*</sup>, Nathaniel H. Thayer<sup>1</sup>, Adam Bohnert<sup>1</sup> and Andrew G. York<sup>1&dagger;</sup></p>
<p class="author_affiliations"><sup>1</sup>Calico Life Sciences LLC, South San Francisco, CA 94080, USA</p>
<p class="contact_email">
<sup>*</sup>Institutional email:
<a href="mailto:amsikking+RR@calicolabs.com" target="_self">amsikking+RR@calicolabs.com</a>
<sup>&dagger;</sup>Institutional email:
<a href="mailto:agy+RR@calicolabs.com" target="_self">agy+RR@calicolabs.com</a>; Permanent email: <a href="mailto:andrew.g.york+RR@gmail.com" target="_self">andrew.g.york+RR@gmail.com</a>
</p>

<h3>Abstract</h3>
<p class="abstract"> High resolution in space and time is often essential for studying life under a microscope. Fast 2D microscopy has been routine for decades, limited by signal levels or detector speed, but 3D is much slower, typically limited by the focusing method. Here we show that remote refocus 

[<a class="citation" href="https://doi.org/10.1016/j.optcom.2007.10.007" title="An optical technique for remote focusing in microscopy; E.J. Botcherby, R. Juškaitis, M.J. Booth and T. Wilson; Optics Communications, vol 281(4), p880-887, (2007)">Botcherby 2007</a>]

removes focusing as a speed limit while adding minimal drawbacks, and we propose that remote refocus is the right technique for most high-speed high-resolution 3D microscopy applications, especially fluorescence. To our knowledge, there is no commercial implementation of remote refocus, so we provide a modular high-performance design to enable others to build their own. We also present the concept, method and rules of remote refocus to help others design their own. Our design gives camera-limited speed (&gt;4.2x10<sup>8</sup> voxels/s) and  diffraction-limited resolution (&lt;270 nm) over a user-specified volume up to 200x200x60 &mu;m<sup>3</sup>. We demonstrate the speed and flexibility of remote refocus using a variety of live biological samples with 3D rates ranging from 2.5-50 volumes per second.</p>

<h3>Intended audience</h3>
<p class="abstract">Microscopy users, developers, engineers and scientists interested in fast volumetric imaging at high resolution. We tried to write the article in an accessible and straightforward fashion; our aim is to lower the barrier to making a good remote refocus, allowing readers to easily replicate our design, or design and build their own with confidence.</p>

<h3>Peer review status</h3>
<p class="abstract">Pre-print published January 11, 2018 doi: XXX (This article is not yet peer-reviewed)</p>

<h3>Introduction</h3>
<h4>Remote refocus removes the primary speed limit of 3D microscopy, with minimal drawbacks</h4>

<p>Revealing the 3D dynamics of living samples is arguably the greatest strength of optical microscopy. To capture these dynamics, we assemble 4D spatiotemporal information from a series of 3D spatial measurements, which are in turn assembled from a series of 2D images

[<a class="citation" href="http://doi.org/10.1016/j.tcb.2011.09.008" title="Microscopy in 3D: a biologist's toolbox; R.S. Fischer, Y. Wu, P. Kanchanawong, H. Shroff and C.M. Waterman; Trends in Cell Biology, vol 21(12), p682–691, (2011) ">Fischer 2011</a>].

2D imaging at "video rate" (~30 frames per second) or above  has been standard in the field for decades

[<a class="citation" href="http://www.springer.com/us/book/9780306455315" title="Video Microscopy - The Fundamentals, second edition; S. Inoué and K. Spring; Springer US, ISBN 978-0-306-45531-5, ISBN 978-1-4613-7686-6 (1997)">Inoué 1997</a>],

but adding the third dimension with standard focusing methods is comparatively slow

[<a class="citation" href="https://doi.org/10.1117/3.2248542" title="Dynamic and Agile Focusing in Microscopy: A Review; S.J. Lukes; SPIE, Vol SL20, ISBN 9781510604438, (2016)">Lukes 2016</a>],

and still represents a challenge for those aiming to achieve the fastest volumetric frame rates at the highest resolutions

[<a class="citation" href="https://doi.org/10.1038/nphoton.2014.323" title="Swept confocally-aligned planar excitation (SCAPE) microscopy for high-speed volumetric imaging of behaving organisms; M.B. Bouchard, V. Voleti, C.S. Mendes, C. Lacefield, W. B. Grueber, R.S. Mann, R.M. Bruno and E.M.C. Hillman; Nature Photonics, vol 9, p113-119, (2015)">Bouchard 2015</a>].</p>

<p>Light flux from the sample sets a fundamental limit on temporal resolution; even a detector with infinite speed and zero noise must wait until it detects enough photoelectrons to form an acceptable image

[<a class="citation" href="https://doi.org/10.1007/978-0-387-45524-2" title="Handbook of Biological Confocal Microscopy, third edition; J. Pawley; Springer US, ISBN 978-0-387-25921-5, eBook ISBN 978-0-387-45524-2, (2006)">Pawley 2006</a>].

Photoelectron-limited operation is rarely achieved due to hardware limitations, which in 2D imaging is often the camera speed (pixels per second) and in 3D imaging is typically the axial (Z) focusing mechanism.</p>

<figure id="Figure_1">
<video controls autoplay loop muted style="height:85%;" id="Figure_1_vid"
 poster="images/Worm_DIC/poster.png">
 <source src="images/Worm_DIC/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<table class="figure_controls">
  <tr>
  <td>Imaging method:</td><td><select id="figure_1_choice" onchange="update_figure_1()">
    <option value="DIC" selected="selected">DIC</option>
    <option value="TLFL">TL/FL</option>
  </select></td><td>(Differential interference contrast, or transmitted light/fluorescence)</td>
  </tr>
</table>
<figcaption><strong>Figure 1: Remote refocus enabling 3D differential interference contrast (DIC) imaging of a worm at 20 volumes per second, and 3D transmitted and flourescence (TL/FL) imaging at 10 volumes per second.</strong> Freely roaming, unparalyzed <em>C. elegans</em> on an agarose pad sandwiched between a standard glass slide and 170 &mu;m coverslip. Volumes consist of 10 Z-slices at 1 &mu;m intervals with bi-directional Z-scanning and 5 ms exposure time per image. The image is cropped to give a 93x90 &mu;m<sup>2</sup> field of view, and the scale bar is 20 &mu;m. Note the figure is interactive, allowing the reader to switch between imaging methods.</figcaption>
</figure>
<p></p>

<p>Many research groups have attacked this focusing speed bottleneck. Notable approaches include imaging multiple focal planes simultaneously via diffractive optics

[<a class="citation" href="https://doi.org/10.1016/S0030-4018(00)00874-9" title="Broadband simultaneous multiplane imaging; P.M. Blanchard and A.H. Greenaway; Optics Communications, vol 183(1-4), p29-36, (2000)">Blanchard 2000</a>,
<a class="citation" href="https://doi.org/10.1109/TNB.2004.837899" title="Simultaneous imaging of different focal planes in fluorescence microscopy for the study of cellular dynamics in three dimensions; P. Prabhat, S.Ram, E.S. Ward and R.J. Ober; IEEE Transactions on NanoBioscience, vol 3(4), p237-242, (2004)">Prabhat 2004</a>]

or light field measurements

[<a class="citation" href="https://doi.org/10.1145/1179352.1141976" title="Light field microscopy; M. Levoy, R. Ng, A. Adams, M. Footer and M. Horowitz; Proceedings of ACM SIGGRAPH, vol 25(3), p924-934, (2006)">Levoy 2006</a>, 
<a class="citation" href="https://doi.org/10.1364/OE.21.025418" title="Wave optics theory and 3-D deconvolution for the light field microscope; M. Broxton, L. Grosenick, S. Yang, N. Cohen, A. Andalman, K. Deisseroth and M. Levoy; Optics Express, vol 21(21), p25418-25439, (2013)">Broxton 2013</a>],

with recent highlights in both approaches

[<a class="citation" href="https://doi.org/10.1038/nmeth.2277" title="Fast multicolor 3D imaging using aberration-corrected multifocus microscopy; S. Abrahamsson, J. Chen, B. Hajj, S. Stallinga, A.Y. Katsov, J. Wisniewski, G. Mizuguchi, P. Soule, F. Mueller, C.D. Darzacq, X. Darzacq, C. Wu, C.I. Bargmann, D.A. Agard, M. Dahan and M.G.L. Gustafsson; Nature Methods, vol 10, p60-63, (2013)">Abrahamsson 2013</a>,
<a class="citation" href="https://doi.org/10.1038/nmeth.2964" title="Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy; Robert Prevedel, Young-Gyu Yoon, Maximilian Hoffmann, Nikita Pak, Gordon Wetzstein, Saul Kato, Tina Schrödel, Ramesh Raskar, Manuel Zimmer,	Edward S Boyden	and Alipasha Vaziri; Nature Methods, vol 11), p727-730, (2014)">Prevedel 2014</a>].

Here we hope to revive a technique of similar vintage, the remote refocus (RR)

[<a class="citation" href="https://doi.org/10.1016/j.optcom.2007.10.007" title="An optical technique for remote focusing in microscopy; E.J. Botcherby, R. Juškaitis, M.J. Booth and T. Wilson; Optics Communications, vol 281(4), p880-887, (2007)">Botcherby 2007</a>],

and suggest that remote refocusing is the right way to acquire fast, high resolution 3D fluorescent images in most cases.</p>

<figure id="Figure_2">
<video controls autoplay loop muted style="width:100%;" id="Figure_2_vid"
 poster="images/Yeast_cyto_FL/poster.png">
 <source src="images/Yeast_cyto_FL/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<figcaption><strong>Figure 2: Remote refocus enabling fluorescent imaging of yeast at 50 volumes per second.</strong> Yeast flow through a microfluidic channel 150 &mu;m wide by 10 &mu;m deep. Volumes consist of 10 z-slices at 1.66 &mu;m intervals, with bi-directional scanning and 2 ms exposure time per 2D image. The image is cropped to give a 207x14 &mu;m<sup>2</sup> field of view, each slice of each volume is displayed simultaneously, and the scale bar is 20 &mu;m.</figcaption>
</figure>
<p></p>

<p>In our hands and others

[<a class="citation" href="https://doi.org/10.1364/OE.16.021843" title="Real-time extended depth of field microscopy; E.J. Botcherby, M.J. Booth, R. Juškaitis and T. Wilson; Optics Express, vol 16(26), p21843-21848, (2008)">Botcherby 2008</a>],

 RR eliminates the 3D bottleneck, reducing axial focusing time below the dead time between camera frames. Remote refocusing's drawbacks are minimal: lower optical efficiency due to four extra lenses in the emission path, and an extended depth of field at the highest volumetric frame rates. Whilst lower efficiency is never desirable, additional lenses in the emission path are tolerable and typical in many microscopes, such as spinning disk units, external filter wheels, etc. Elongated depth of field is either beneficial or undesirable depending on the application

[<a class="citation" href="https://doi.org/10.1364/OE.16.021843" title="Real-time extended depth of field microscopy; E.J. Botcherby, M.J. Booth, R. Juškaitis and T. Wilson; Optics Express, vol 16(26), p21843-21848, (2008)">Botcherby 2008</a>],

 but only becomes relevant at the highest volumetric rates, when RR piezo settling times exceed the rolling time of our camera (see <a href="./appendix.html#Design">design</a> section for details).<p>

<p>In contrast, multifocus 

[<a class="citation" href="https://doi.org/10.1038/nmeth.2277" title="Fast multicolor 3D imaging using aberration-corrected multifocus microscopy; S. Abrahamsson, J. Chen, B. Hajj, S. Stallinga, A.Y. Katsov, J. Wisniewski, G. Mizuguchi, P. Soule, F. Mueller, C.D. Darzacq, X. Darzacq, C. Wu, C.I. Bargmann, D.A. Agard, M. Dahan and M.G.L. Gustafsson; Nature Methods, vol 10, p60-63, (2013)">Abrahamsson 2013</a>]

and light field microscopy

[<a class="citation" href="https://doi.org/10.1038/nmeth.2964" title="Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy; Robert Prevedel,	Young-Gyu Yoon,	Maximilian Hoffmann, Nikita Pak, Gordon Wetzstein, Saul Kato, Tina Schrödel, Ramesh Raskar, sManuel Zimmer,	Edward S Boyden	and Alipasha Vaziri; Nature Methods, vol 11), p727-730, (2014)">Prevedel 2014</a>]

completely eliminate axial focusing time, but also reduce camera-limited imaging speed (i.e. voxels per second). Multifocus microscopy's X, Y, and Z fields of view can't be adjusted to match the sample, which wastes time measuring empty voxels in undersized samples, and requires slow mechanical focusing for oversize samples. Light field microscopy yields even fewer voxels per second than multifocus microscopy, because it measures multiple camera pixels to characterize one Nyquist-limited voxel; other drawbacks include degraded resolution and mandatory post-processing. These techniques are therefore faster than RR when the bottleneck is RR focusing time, but slower when the bottleneck is the pixel rate of the camera. In our experience with well-engineered RR fluorescence microscopes, the bottleneck is always the camera. In addition, multifocal and light field microscopy combine awkwardly with powerful 3D techniques like light-sheet or spinning-disk microscopy, which couple elegantly with remote refocus

[<a class="citation" href="https://doi.org/10.1364/OE.16.021843" title="Real-time extended depth of field microscopy; E.J. Botcherby, M.J. Booth, R. Juškaitis and T. Wilson; Optics Express, vol 16(26), p21843-21848, (2008)">Botcherby 2008</a>,

<a class="citation" href="https://doi.org/10.1364/OE.16.020306" title="Optically sectioned imaging by oblique plane microscopy; C. Dunsby; Optics Express, vol 16(25), p20306-20316, (2008)">Dunsby 2008</a>].
</p>

<p>Given the importance of fast 3D microscopy, and the power and flexibility of RR, we're surprised RR isn't more popular. The <a href="./appendix.html#History">history</a> of RR shows many clever technical innovations, but few biological applications, and no commercial implementations. We speculate RR suffers from two problems: surprising pitfalls during design and construction, and a lack of advertising. We hope our design empowers builders to confidently make their own RR, and we hope that 3D videos of <em>C. elegans</em> at 20 volumes per second (Figure 1) and flowing yeast at 50 volumes per second (Figure 2) entice microscope users to try RR for their own high-speed imaging challenges. Most of all, we hope to inspire microscope manufacturers to commercialize and disseminate remote refocus as the "gold standard" solution for fast 3D fluorescence microscopy.</p>

<h4>The why and how of remote refocus</h4>

<p></p>
<p>The motivation for fast focusing is clear, but the advantages (or indeed, the meaning) of ‘remote’ refocusing may not be obvious. Standard microscopes select their image plane (dotted line, Figure 3a) by moving either the objective lens or the sample. This is convenient and simple, but the high inertia of these elements requires a high-power Z-actuator to achieve agile motion, which combines awkwardly with typical crowded multi-objective turrets. In addition, high-resolution imaging requires immersion media like oil or water, which couples rapid vibration of the objective to the coverslip, disturbing the sample and blurring the image at high focusing speeds (Figure 3c). In our experience, any optimization to improve this focusing speed 

[<a class="citation" href="https://doi.org/10.1038/nmeth.2687" title="Instant super-resolution imaging in live cells and embryos via analog image processing; Andrew G. York, Panagiotis Chandris, Damian Dalle Nogare, Jeffrey Head, Peter Wawrzusin, Robert S. Fischer, Ajay Chitnis &amp; Hari Shroff; Nature Methods 10, 1122–1126 (2013)">York 2013, Sup. Fig. 6</a>]

is highly dependent on both the sample and the objective lens, and must be re-optimized to maintain high performance whenever either changes.</p>

<figure id="Figure_3">
<video controls autoplay loop muted style="width:100%;" id="Figure_3_vid"
 poster="images/RR_animation/slowposter.png">
 <source src="images/RR_animation/slow.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<video controls autoplay loop muted style="width:100%;" id="Figure_4_vid"
 poster="images/RR_animation/fastposter.png">
 <source src="images/RR_animation/fast.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<figcaption><strong>Figure 3: Typical focusing vs. remote refocus at moderate and high acquisition speeds.</strong> <strong>(a)</strong> Typical focusing: to change the focal plane (horizontal dotted line), the objective moves with respect to the sample. Immersion oil or water (blue) couples this motion to the sample. <strong>(b)</strong> Remote re-focus: the primary objective and sample don't move during focusing, which prevents mechanical coupling. <strong>(c)</strong> At high speeds, typical focusing with immersion fluid disturbs the sample, degrading or even preventing 3D imaging. <strong>(d)</strong> Remote refocus allows fast 3D images because the sample is isolated from focus-related motion.</figcaption>
</figure>
<p></p>

<p>Refocusing remotely leaves the sample and primary objective stationary (Figure 3b), isolating the sample from mechanical disturbance at high speed (Figure 3d). Because the moving part is now outside the microscope, optimizations for fast focusing become indpendent of the sample and the primary objective, simplifying life for the microscope's user. The 'bolt-on' nature of the module doesn't interfere with the normal operation of the microscope, and even provides a convenient space for a fast external filter wheel without the need for an additional telescope.</p>

<p>A detailed description of RR theory is elegantly presented in the original paper

[<a class="citation" href="https://doi.org/10.1016/j.optcom.2007.10.007" title="An optical technique for remote focusing in microscopy; E.J. Botcherby, R. Juškaitis, M.J. Booth and T. Wilson; Optics Communications, vol 281(4), p880-887, (2007)">Botcherby 2007</a>],

and will not be re-visited here. We do however provide a straightforward <a href="./appendix.html#Concept_rules_and_simulation">concept, rules and simulation</a> section in the <a href="./appendix.html">Appendix</a> for those looking to build their own RR, which highlights potential pitfalls. We also give a brief summary of the <a href="./appendix.html#History">history</a> of the technique which may help the reader frame its use in the field of microscopy and understand how the RR version presented here fits into the story.</p>

<h3>Results</h3>
<h4>Large volumes with uncompromised resolution</h4>

<p>We designed our remote refocus to couple to a typical microscope stand and produce diffraction-limited images using a 60x 1.4 numerical aperture (NA) oil immersion primary objective (Figure 4). Because our design's Z-drive can make small steps (0.1-1 &mu;m) faster than the rolling time of modern sCMOS cameras at full field (&lt;10 ms), the system imaging speed is either camera-limited or photoelectron-limited in this regime. This section describes the optical performance; for a detailed description of the module, see the <a href="./appendix.html#Design">design</a> and <a href="./appendix.html#Build">build</a> sections of the <a href="./appendix.html">Appendix</a>.</p>

<figure id="Figure_4">
<img src="images/RR_images/Fast_3D_widefield_microscope_1.0_wireframe.png" alt="Figure 4" id="Figure_4_jpg_1" style="width:100%;">
<img src="images/RR_images/Remote_re-focus_1.2_rendered.jpg" alt="Figure 4" id="Figure_4_jpg_2" style="width:49.5%;">
<img src="images/RR_images/Remote_re-focus_1.2_photo.jpg" alt="Figure 4" id="Figure_4_jpg_3" style="width:48.1%;">
<figcaption><strong>Figure 4: Remote re-focus design.</strong> <strong>(a)</strong> A wireframe image of the instrument showing that it easily couples to the side port of a normal microscope stand with space left for a full sized incubation chamber and a fast filter wheel. <strong>(b)</strong> A rendered image of the full opto-mechanically designed system, optimised for a Nikon 60x 1.4 NA oil immersion objective (and giving excellent performance with a Nikon 40x 0.95 NA air objective). <strong>(c)</strong> A photograph of the final build used to generate the data presented in this article.</figcaption>
</figure>
<p></p>

<p>
We characterize image quality via <a href="http://argolight.com/">Argolight's</a> SIM slide, with variable-spacing fluorescent features (down to 30 nm separation) which allow us to quickly and accurately measure spatial resolution over the full 3D field-of-view.

We eschewed traditional labour-intensive volumetric PSF characterisation via beads because of the rigor of the original RR paper

[<a class="citation" href="https://doi.org/10.1016/j.optcom.2007.10.007" title="An optical technique for remote focusing in microscopy; E.J. Botcherby, R. Juškaitis, M.J. Booth and T. Wilson; Optics Communications, vol 281(4), p880-887, (2007)">Botcherby 2007</a>],

the comprehensive testing of subsequent builders

[<a class="citation" href="https://doi.org/10.1073/pnas.1109111108" title="Three-dimensional imaging and photostimulation by remote-focusing and holographic light patterning; F. Anselmi, C. Ventalon, A. Bègue, D. Ogden and V. Emiliani; PNAS, vol 108(49), p19504-19509, (2011)">Anselmi 2011</a>,
 
<a class="citation" href="https://doi.org/10.1364/AO.53.003473" title="Remote-focusing microscopy with long working distance objective lenses; Y. Qi, M. Lei, Y. Yang, B. Yao, D. Dan, X. Yu, S. Yan and T. Ye; Applied Optics, vol 53(16), p3473-3478, (2014)">Qi 2014</a>],

and the thorough optical design work implemented here.</p>
 
<p> Our system yields minimally distorted images across the entire 200x200x60 &mu;m<sup>3</sup> volume (Figure 5), using a standard GFP filter cube; note the clearly resolved line pairs, which are separated by 750 nm. We construct a "virtual" 3D test object from a 2D resolution target by moving the microscope's primary objective Z-drive and refocusing via the RR piezo (see the <a href="./appendix.html#Acquisition">acquisition</a> section for details and raw data).</p>
 
 <figure id="Figure_5">
<img src="images/SIM_target/default.png" alt="Figure 5" id="Figure_5_png" style="width:100%;">
<table class="figure_controls">
  <tr>
  <td>Microscope de-focus:</td><td><select id="figure_5_microscope" onchange="update_figure_5()">
    <option value="04">+30</option>
    <option value="03">+15</option>
    <option value="02" selected="selected" >0</option>
    <option value="01">-15</option>
    <option value="00">-30</option>
  </select></td><td>(&mu;m; at 0, the sample is in focus on the microscope eyepieces)</td>
  </tr>
  <tr>
  <td>RR de-focus:</td><td><select id="figure_5_RR" onchange="update_figure_5()">
    <option value="08">+2.0</option>
    <option value="07">+1.5</option>
    <option value="06">+1.0</option>
    <option value="05">+0.5</option>
    <option value="04">0.0</option>
    <option value="03">-0.5</option>
    <option value="02" selected="selected">-1.0</option>
    <option value="01">-1.5</option>
    <option value="00">-2.0</option>
  </select></td><td>(&mu;m; at 0, the RR approximately cancels the primary objective's defocus)</td>
  </tr>
  </table>
<figcaption><strong>Figure 5: RR delivers minimal distortion across the 3D field of view.</strong> Images of an engineered flourescent target (Argolight SIM slide) show the remote refocus's large (200x200x60 &mu;m<sup>3</sup>) imaging volume, with minimal distortion and clearly resolvable line pairs separated by 750 nm across the whole volume. We used the microscope Z-drive to de-focus the sample, and then the RR piezo to re-focus, scanning the full 3D design volume of the instrument. Note the figure is interactive, allowing the reader to tune both the microscope objective and RR piezo position to inspect 3D image quality. Scale bar is 20 &mu;m.</figcaption>
</figure>
<p></p>

<p>To quantify resolution, we translated finely spaced resolution lines through the field of view. Consistent with our expections of diffraction-limited performance within the design volume, the RR does not degrade resolution, easily resolving lines separated by 270 nm across the entire volume (Figure 6), and 240 nm near the center (see <a href="./appendix.html#Design">design</a> section for details). Note the classic Rayleigh limit \(\frac{0.61\lambda}{NA}\) predicts ~230 nm resolution using this filter cube, which even unmodified microscopes rarely achieve in our experience.</p>

<figure id="Figure_6">
<img src="images/SIM_lines_center/default.png" alt="Figure 6" id="Figure_6_png" style="width:100%;">
<table class="figure_controls">
  <tr>
  <td>Sample position:</td><td><select id="figure_6_fov" onchange="update_figure_6()">
    <option value="SIM_lines_center" selected="selected">centered</option>
    <option value="SIM_lines_mid">half radius</option>
    <option value="SIM_lines_edge">edge</option>
  </select></td><td>(within the microscope's full field of view)</td>
  </tr>
  <tr>
  <td>Microscope de-focus:</td><td><select id="figure_6_microscope" onchange="update_figure_6()">
    <option value="12">+30</option>
    <option value="11">+25</option>
    <option value="10">+20</option>
    <option value="09">+15</option>
    <option value="08">+10</option>
    <option value="07">+5</option>
    <option value="06" selected="selected" >0</option>
    <option value="05">-5</option>
    <option value="04">-10</option>
    <option value="03">-15</option>
    <option value="02">-20</option>
    <option value="01">-25</option>
    <option value="00">-30</option>
  </select></td><td>(&mu;m; at 0, the sample is in focus on the microscope eyepieces)</td>
  </tr>
   <tr>
  <td>RR de-focus:</td><td><select id="figure_6_RR" onchange="update_figure_6()">
    <option value="16">+2.00</option>
    <option value="15">+1.75</option>
    <option value="14">+1.50</option>
    <option value="13">+1.25</option>
    <option value="12">+1.00</option>
    <option value="11">+0.75</option>
    <option value="10">+0.50</option>
    <option value="09">+0.25</option>
    <option value="08" selected="selected">0.00</option>
    <option value="07">-0.25</option>
    <option value="06">-0.50</option>
    <option value="05">-0.75</option>
    <option value="04">-1.00</option>
    <option value="03">-1.25</option>
    <option value="02">-1.50</option>
    <option value="01">-1.75</option>
    <option value="00">-2.00</option>
  </select></td><td>(&mu;m; at 0, the RR approximately cancels the primary objective's defocus)</td>
  </tr> 
  </table>
<figcaption><strong>Figure 6: RR delivers uncompromised resolution across the design volume.</strong> Finely separated flourescent lines (Argolight SIM slide) show the resolution of our RR design. The pattern consists of 14 line pairs that range from fully overlapped (top) to a separation of 390 nm (bottom) in 30 nm steps. The data shows a 200x200x60 &mu;m<sup>3</sup> volume with resolving power better than 270 nm line separation, and better than 240 nm in the central volume. We used the microscope Z-drive to de-focus the sample, and then the RR piezo to re-focus, scanning the full 3D design volume of the instrument. Note the figure is interactive, allowing the reader to tune both the microscope objective and RR piezo position to inspect 3D image quality. Scale bar is 20 &mu;m.</figcaption>
</figure>
 
<p></p>
<p>Broadband optical efficiency tests show the <a href="./appendix.html#Figure_A6">RR throughput is &gt;73%</a>, and stability tests show a <a href="./appendix.html#Figure_A5">mechanical drift of ~150 nm/hour</a> (see the <a href="./appendix.html#Design">design</a> section for details). Finally, Figure 7 explicitly demonstrates volumetric imaging via a 3D rendering of an Argolight structure that consists of an array of rings separated by 5 &mu;m in each axis.</p>

<figure id="Figure_7">
<video controls autoplay loop muted style="width:100%;" id="Figure_7_vid"
 poster="images/SIM_3D_projected/poster.png">
 <source src="images/SIM_3D_projected/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<figcaption><strong>Figure 7: Volumetric imaging capability of remote refocus illustrated via 3D structures on the Argolight SIM slide.</strong> The pattern consists of a 3D array of 9x9x9 rings separated by 5 &mu;m in X, Y, and Z. We acquired the data by focusing the microscope Z-drive onto the top plane, and then used the RR piezo to take the Z-stack. We processed the stack with ImageJ to give 3D projections from various angles. Scale bar is 20 &mu;m.</figcaption>
</figure>

<h4>Much faster than standard focusing, especially with non-rigid and delicate samples</h4>

<p>Having established excellent image quality, we next measured the speed of our remote refocus (Figure 8) using a series of standard samples: a glass slide with chrome graticule (very rigid), a glass slide with agarose pad and coverslip (semi-rigid), a plastic dish with coverslip bottom (semi-flexible) and a microfluidic chip (very flexible). We compare our RR's focusing speed vs. standard focusing methods: the motorized primary objective of a premium microscope stand, and a high-performance Z-piezo stage insert. For each sample, we set the microscope stand primary objective to an initial 10 &mu;m de-focus, and used each device in turn to focus the sample and then return to its initial position. The allotted focusing times for the RR piezo (15 ms) and the piezo stage insert (50 ms) were determined by their <a href="./appendix.html#Figure_A4">measured</a> 10 &mu;m step-and-settle times (see the <a href="./appendix.html#Acquisition">acquisition</a> section for details). The focusing time of the motorized objective (~100 ms) is bottlenecked by serial port communication latency. Note that serial port communication is the primary bottleneck for most microscopy systems; we encourage anyone interested in fast acquisition to implement hardware synchronization <a href="https://github.com/AndrewGYork/tools/blob/master/ni.py">via an analog-out card</a>.</p>

<figure id="Figure_8">
<img src="images/Samples/graticule.jpg" alt="Figure 8" id="Figure_8a_svg" style="width:45%;">
<img src="images/Samples/uFchip.jpg" alt="Figure 8" id="Figure_8b_svg" style="width:45%;">
<video controls autoplay loop muted style="width:45%;" id="Figure_8a_vid"
 poster="images/Graticule/poster.png">
 <source src="images/Graticule/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<video controls autoplay loop muted style="width:45%;" id="Figure_8b_vid"
 poster="images/uFchip/poster.png">
 <source src="images/uFchip/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<table class="figure_controls">
  <tr>
  <td>Sample choice:</td><td><select id="figure_8_sample_choice" onchange="update_figure_8()">
    <option value="graticule" selected="selected">Graticule (very rigid) and &mu;Fluidic chip (very flexible)</option>
    <option value="agarose">Agarose pad (semi-rigid) and Dish (semi-flexible)</option>
  </select></td>
  </tr>
</table>
<figcaption><strong>Figure 8: RR delivers faster focusing and less sample disturbance vs. standard techniques, for a range of standard samples.</strong> 

Each column of the figure shows one sample type. The top panel is a photo of the sample, showing how it was mounted. The middle panel shows a 1000 fps video of focusing performance for a 10 &mu;m motion of the microscope stand (first motion), the piezo stage insert (second motion), and the RR (third motion) for that sample. The bottom panel shows a kymograph of image intensity vs. space (left/right) and time (up/down) of a central horizontal line of pixels from the corresponding video. The video illustrates the lateral sample disturbance due to each method, and the kymograph highlights the axial focusing speed. Note that the figure is interactive, allowing the reader to switch between displaying either: <strong>(1)</strong> a very rigid graticule (left) and a very flexible microfluidic chip (right), or <strong>(2)</strong> a somewhat rigid coverslip/agarose pad/glass slide sample (left, like the one shown in Figure 1) and a somewhat flexible plastic dish with bonded 170 &mu;m coverglass and a sprinkling of aluminum particles for imaging contrast (right).

<!--

This text should probably be in the body rather than the caption, and I don't want to delete it until I'm sure:

The figure is interactive and consists of 4 sub figures that are paired: (graticule + microfluidic chip) and (agarose pad + dish), where each sub figure consists of 3 panels: a video of focusing at 1000fps (top), intensity vs time for a slice of the video (middle) and a photo of the sample (bottom).  The microfluidic chip consists of a finely featured PDMS device bonded to standard 170&mu;m coverglass and was designed and tested for high resolution microscopy of live biology in 4D. Here the microscope and stage insert are unable to focus on the sample at high speed due to the coupling of the oil which causes the sample to flex, where as the remote re-focus can operate unimpeded and shows huge (27x) gains in speed. The agarose slide consists of a standard glass slide with a ~1mm agarose pad and <em>C. elegans</em> under a standard 170&mu;m coverslip. The relatively slow microscope stand was able to focus on the worm in a similar way to the graticule (some xy motion) but because the agarose is not fully rigid the faster stage insert could not reach a sharp focus in the time interval (the remote re-focus was unimpeded). The dish sample consists of a premium manufactured plastic dish with bonded 170&mu;m converglass and a sprinkling of aluminium particles for imaging. This sample was more flexible than the agarose pad and so the microscope and stage insert struggled to find sharp focus and predictably the remote re-focus was unaffected.
-->
</figcaption></figure>
<p></p>

<p>The graticule is an opaque chrome mask deposited on a small, thick glass slide, supported by a larger solid metal slide. This stiff, well-clamped sample is nearly undisturbed by the immersion oil during fast focusing via the piezo stage insert (50 ms), and it may not be obvious what advantage RR offers in this regime. However, the RR is still &gt;3x faster (15 ms), because RR lets us use a powerful, bulky piezo, <a href="./appendix.html#Figure_A4">tuned to drive a fixed mass</a>. This large tuned piezo is ill-suited for conventional focusing: it doesn't fit typical microscope nosepieces, its power cable antagonizes objective turret rotation, and it would need retuning every time the sample or primary objective changed.</p>

<p>The advantages of RR increase for less rigid samples, which are more typical in our experience. For example, the agarose sample sandwiches <em>C. elegans</em> on a ~1 mm agarose pad between a standard glass slide and a 170 &mu;m coverslip, or the dish sample, a standard manufactured plastic dish with bonded 170 &mu;m coverglass and a sprinkling of aluminium particles for imaging contrast. The flexibility of the agarose prevents the piezo stage insert from reaching sharp focus in the alloted time, and even more so for the dish. Predictably, the remote refocus was unaffected by the flexibility or mass of either sample.</p>

<p>The microfluidic chip is a finely featured polydimethylsiloxane (PDMS) device bonded to a 60x50 mm<sup>2</sup> 100 &mu;m coverglass, designed for long-term high resolution 3D microscopy of living yeast. The sample is inherently flexible, and moving the microscope objective or stage insert bends it substantially via the immersion oil, requiring more than 400 ms settling time. Of course this is irrelevant to the RR, which gives an impressive 27x speed advantage in this case. This eliminates a common tension between microscope builders and microscope users; it's easy for the builder to criticize a sample for being too flexible, but redesigning a complex sample should not be taken lightly. Our colleagues are delighted that the remote refocus saves them from choosing between slow image acquisition or laborious chip redesign, and we suspect many others would have a similar experience.</p>

<h4>Dynamic 4D biology</h4>

<p>Having established excellent optical and mechanical performance, we next explore the utility and the limits of remote refocus for imaging living organisms at high spatiotemporal resolution. Samples include <em>C. elegans</em> roaming an agarose pad imaged at up to 20 volumes/s (Figure 1), yeast cells flowing in microfluidic channels imaged at up to 50 volumes/s (Figures 2 and 9), and waterborne protozoa freely moving in a 3D volume imaged at up to 16.7 volumes/s (Figure 9).</p>

<figure id="Figure_9">
<video controls autoplay loop muted style="width:100%;" id="Figure_9_vid"
 poster="images/Amoeba/poster.png">
 <source src="images/Amoeba/figure.mp4" type="video/mp4">
 Your browser doesn't support HTML5 MP4 video.`
</video>
<table class="figure_controls">
  <tr>
  <td>Sample choice:</td><td><select id="figure_9_choice" onchange="update_figure_9()">
    <option value="amoeba" selected="selected">Amoeba</option>
    <option value="3color">Yeast - 3 color</option>
    <option value="flower">Contaminant - <em>Epistylis</em>?</option>
    <option value="food">Contaminant - <em>Paramecium</em>?</option>
    <!--
    <option value="2color">Yeast - 2 color</option>
    <option value="paramecium">Paramecium</option>
    <option value="spiro">Spirostomum</option>
    -->
  </select></td>
  </tr>
</table>
<figcaption><strong>Figure 9: Demonstrations of 4D biological imaging via RR.</strong> 
 Amoeba: imaged with DIC in a 384 well plate with 170 &mu;m coverglass, 4 slices in 5 &mu;m steps with 20 ms exposure times giving 12.5 volumes/s.
 Yeast 3 color: imaged with transmitted light, GFP and RFP flowing in a 150 &mu;m wide microfluidic channel with a depth of 10 &mu;m, 12 slices in 0.5 &mu;m steps with 6 ms exposure times giving 4.6 volumes/s.
 Contaminant - <em>Epistylis</em>? and Contaminant - <em>Paramecium</em>?: Interesting contaminants found while searching a <em>Spirostomum</em> sample, imaged with DIC in a 384 well plate with 170 &mu;m coverglass, 6 slices in 10 &mu;m steps with 10 ms exposure times giving 16.7 volumes/s.
 The field of view varies between samples (see original data in the <a href="./appendix.html#Acquisition">acquisition</a> section) but the scale bar is 20 &mu;m in all cases.</figcaption>
</figure>
<p></p>

<p>RR enables whole-organism DIC microscopy fast enough to 'freeze' the motion of <em>C. elegans</em> pharyngeal pumping (Figure 1 with <code>Imaging method: DIC</code>) or <em>Amoeba proteus</em> internal flow (Figure 9 with <code>Sample choice: Amoeba</code>) in 3D. Of course, fast focusing is necessary but not sufficient for fast 3D microscopy, and we must manage many potential speed limits. For example, adding a fluorescent channel (Figure 1 with <code>Imaging method: TL/FL</code>) requires twice as many camera frames, cutting volumetric rates in half. Since DIC collection optics block ~50% of fluorescent emission, we typically switch to transmitted light (TL) when using fluorescence, rather than lose speed from dim fluorescence or slow mechanical filter changing.</p>

<p>RR combined with <a href="./appendix.html#Additional_equipment">fast-switching LED illumination</a> and an appropriate filter set allows high-speed multi-color imaging of rapidly flowing yeast (Figure 9 with <code>Sample choice: Yeast - 3 color</code>). Note that even at 4.6 volumes per second, the flow still moves significantly during each volume. In this case, our speed limit isn't focusing, signal rates, or illumination intensity; it's the camera. Current sCMOS chips measure at most 2x10<sup>5</sup> lines per second, independent of the number of pixels per line. Cropping our camera to a small number of long lines (Figure 2) enables 50 volumes per second, fast enough to 'freeze' this rapid flow without sacrificing pixels per second, and orienting the flow perpendicular to the camera lines maximizes yeast per second measured by this '3D cytometer'.</p>

<p>Piezo motion potentially elongates the depth of field when the piezo step-and-settle time (~10 ms here) exceeds the camera "dead time" between illuminations (~5 &mu;s per line here). For example, in Figure 2 we cropped the camera vertically to 200 lines, and each 2 ms exposure consists of a 1 ms dead time followed by 1 ms of illumination (500 frames/s). We moved the RR piezo at a constant 1.66 mm/s velocity during each bi-directional volume, extending the effective depth of field by 1.66 &mu;m, ~2 fold the static depth of field estimated via \(\frac{2\lambda n}{\text{NA}^2}\) (~750 nm). We found the resulting Z-resolution acceptable, but there are ways to circumvent the issue, e.g. a larger piezo, a lighter RR objective, a more sophisticated control voltage; perhaps simplest is to use a shorter illumination time.</p>

<p>While searching a <em>Spirostomum</em> sample, we incidentally acquired two interesting videos of "contaminant" species that highlight limits of our design. We imaged the first species (Figure 9 with <code>Sample choice: Contaminant - <em>Epistylis</em>?</code>) at 16.7 volumes/s. While the main body of the creature is almost stationary during one volume, the cilia near the 'mouth' show motion blur during a single 10 ms 2D exposure. This suggests we'd need to image at least 200-300 volumes/s to 'freeze' this rapid motion in 3D, which approaches the resonant frequency of our piezo and the limit of our camera's frame rate for useful fields of view. The second species (Figure 9 with <code>Sample choice: Contaminant - <em>Paramecium</em>?</code>) is even faster, moving its entire body almost this quickly. We suspect simultaneous multiplane methods like multifocus or light-field microscopy would be better suited for imaging such rapid motion; even with volumetric frame rates no faster than RR, at least they could avoid motion blur during one volume by strobing sufficiently bright illumination for a sufficiently short time.</p>

<h3>Discussion</h3>
<h4>Paths towards widespread adoption of remote refocus</h4>

<p>We believe that RR is ripe for widespread adoption, cleanly and flexibly addressing a common challenge without introducing other problems. Many microscopes could benefit from decoupling the focusing mechanism from the sample via remote refocus, especially when the sample is sensitive and high spatiotemporal resolution is required. RR's modularity is a great strength; you can treat it as a "black box" attached directly before your camera to eliminate focusing speed limits, without interfering mechanically or optically with other features of your microscope, ranging from objective turrets and emission filters to spinning-disk units or even structured illumination microscopy. To our knowledge, the foundational patent claiming aspects of the RR design

[<a class="citation" href="https://patents.google.com/patent/US8144395B2/en" title="Focusing apparatus and method; Tony Wilson, Rimvydas Juskaitis, Martin James Booth, Edward Botcherby, assigned to Isis Innovation Limited; U.S. Patent No. 8,498,048 (2013)">Wilson 2013</a>]

is available for licensing, and we encourage microscope vendors to explore this possibility.</p>

<p>For some applications, we would still recommend other approaches. For example, RR enables high volumetric frame rates, but doesn't deliver truly simultaneous "snapshot" volumetric imaging, unlike multifocus or light-field microscopy. Although the hardware cost of our design (~$30k) is a fraction of a high-end fluorescence microscope's price, light-field microscopy's hardware is even cheaper, a simple microlens array (~$1k) and a powerful computer. Of course, our RR's price is dominated by the piezo and objectives, and could be  <a href="./appendix.html#Parts">redesigned to minimize cost</a>.</p>

<p>Perhaps the greatest obstacle to building your own RR is getting software to control the hardware. We write our own <a href="./appendix.html#Example_code">Python code</a> to control our hardware. This approach is powerful, flexible, and <a href="https://github.com/AndrewGYork/tools">open-source</a>, but our code is poorly documented and very specific to our needs. We encourage anyone interested in learning this approach to contact or visit <a href="mailto:andrew.g.york+remote_refocus@gmail.com">Andrew York</a>, although we caution that this is only appropriate for people who are proficient in <a href="https://python.org">Python</a> programming, or serious about achieving proficiency.</p>


We'd especially like to see a <a href="https://micro-manager.org/">&mu;Manager device adapter</a> 

[<a class="citation" href="https://doi.org/10.14440/jbm.2014.36" title="Advanced methods of microscope control using &mu;Manager software; Arthur D Edelstein, Mark A Tsuchida, Nenad Amodaj, Henry Pinkard, Ronald D Vale, and Nico Stuurman; Journal of Biological Methods 1(2):e10, (2014)">Edelstein 2014</a>]

for our RR design. Since the controller for our piezo can act as an analog-out card programmed via the serial port, this is potentially straightforward. If other groups share this interest, please contact us; we are not expert &mu;Manager hackers, but we may be able to contribute attention and resources to this effort.</p>

<p>Most of all, we want to see the field of microscopy advance, and we're eager to see others adopt remote refocus. If you're considering building your own, we'd enjoy hearing about your plans and your design, and we may be able to offer useful advice.</p>

<h3>Acknowledgements</h3>

<p>This work was funded and supported by <a href="https://www.calicolabs.com/">Calico Life Sciences LLC</a> and we would like to acknowledge the fantastic research environment that has been created here by the senior staff. We would also like to specifically thank the yeast and worm groups within the company for helping prepare and provide the biological samples presented.</p>

<p>Special praise is given to the business development team at Calico for pursuing and arranging all of our external collaborations. In this regard we would like to specifically acknowledge our close collaborations with <a href="https://www.nikoninstruments.com">Nikon</a> and <a href="http://www.leica-microsystems.com/">Leica</a> who made it possible to create a high quality instrument design and we look forward to future projects with these partners.</p>

<p>We also thank <a href="https://www.physikinstrumente.com">Physik Instumente</a>, <a href="http://lumencor.com/">Lumencor</a> and <a href="https://www.pco.de/">PCO</a> for their detailed assistance in using their products, and our local suppliers <a href="http://www.zeradevelopment.com/">Zera Development</a> and <a href="http://www.markoptics.com/">Mark Optics</a> for their high quality work and readily available technical support.</p>

<h3><a href="./appendix.html">Appendix</a></h3>
<p>Additional details and discussion can be found in the <a href="./appendix.html">appendix</a>, which is also referenced via hyperlinks throughout this article.</p>

<noscript>
<h3>Your browser doesn't seem to support Javascript. This document uses Javascript to generate a reference list, which would normally be displayed here. Either activate Javascript, or use the "Download PDF" link above if you want to see the reference list.</h3></noscript>

</section>
<footer>
  <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="border-width:0" src="./images/cc_by_4p0.png"></a>

  <p><small>Hosted on <a href="https://pages.github.com">GitHub Pages</a></small></p>
</footer>
</div>
 <!--[if !IE]><script>fixScale(document);</script><![endif]-->
</body>
</html>
